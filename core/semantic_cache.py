"""
è¯­ä¹‰ç¼“å­˜æ¨¡å— - åŸºäº Redis å’Œ Embedding çš„æ™ºèƒ½ç¼“å­˜
ä½œè€…: RAG é¡¹ç›®å›¢é˜Ÿ
æè¿°: ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦è¿›è¡Œé—®é¢˜åŒ¹é…ï¼Œæ”¯æŒç”¨æˆ·ç¡®è®¤æœºåˆ¶
"""

import redis
import numpy as np
import hashlib
import json
import logging
from typing import Optional, Dict, List, Tuple
from datetime import datetime

from config import config


logger = logging.getLogger(__name__)


class SemanticCache:
    """
    è¯­ä¹‰ç¼“å­˜ç±»

    åŠŸèƒ½:
    - åŸºäº Embedding çš„è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…
    - ä¸‰å±‚é˜ˆå€¼ç­–ç•¥ï¼ˆç›´æ¥è¿”å›/ç”¨æˆ·ç¡®è®¤/æœªå‘½ä¸­ï¼‰
    - LRU ç¼“å­˜æ·˜æ±°
    - çƒ­é—¨é—®é¢˜ç»Ÿè®¡
    - ç›¸ä¼¼é—®é¢˜èšç±»
    """

    def __init__(self, embedding_engine):
        """
        åˆå§‹åŒ–è¯­ä¹‰ç¼“å­˜

        å‚æ•°:
            embedding_engine: åµŒå…¥å¼•æ“å®ä¾‹ï¼ˆç”¨äºè®¡ç®—é—®é¢˜å‘é‡ï¼‰
        """
        try:
            # Redis è¿æ¥é…ç½®
            redis_config = {
                'host': config.REDIS_HOST,
                'port': config.REDIS_PORT,
                'db': config.REDIS_DB,
                'decode_responses': False,  # ä¿ç•™äºŒè¿›åˆ¶æ•°æ®ï¼ˆç”¨äºå­˜å‚¨ embeddingï¼‰
                'socket_timeout': 5,
                'socket_connect_timeout': 5
            }

            # åªæœ‰åœ¨å¯†ç éç©ºæ—¶æ‰æ·»åŠ å¯†ç å‚æ•°
            if config.REDIS_PASSWORD:
                redis_config['password'] = config.REDIS_PASSWORD

            self.redis = redis.Redis(**redis_config)

            # æµ‹è¯•è¿æ¥
            self.redis.ping()
            self._available = True
            logger.info(f"âœ… Redis è¿æ¥æˆåŠŸ: {config.REDIS_HOST}:{config.REDIS_PORT}")

        except (redis.ConnectionError, redis.TimeoutError) as e:
            logger.warning(f"âš ï¸ Redis è¿æ¥å¤±è´¥ï¼Œç¼“å­˜åŠŸèƒ½å·²ç¦ç”¨: {e}")
            self._available = False
            self.redis = None

        # åµŒå…¥å¼•æ“
        self.embedding_engine = embedding_engine

        # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä»é…ç½®è¯»å–ï¼‰
        self.threshold_direct = config.CACHE_THRESHOLD_DIRECT      # 0.98 - ç›´æ¥è¿”å›
        self.threshold_confirm = config.CACHE_THRESHOLD_CONFIRM    # 0.95 - éœ€è¦ç¡®è®¤

        # ç¼“å­˜é…ç½®
        self.cache_ttl = config.CACHE_TTL                         # è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        self.max_cache_size = config.CACHE_MAX_SIZE               # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°

        if self._available:
            logger.info(f"ğŸ“¦ ç¼“å­˜é…ç½® - ç›´æ¥é˜ˆå€¼: {self.threshold_direct}, "
                       f"ç¡®è®¤é˜ˆå€¼: {self.threshold_confirm}, "
                       f"TTL: {self.cache_ttl}s, "
                       f"æœ€å¤§å®¹é‡: {self.max_cache_size}")

    def is_available(self) -> bool:
        """æ£€æŸ¥ç¼“å­˜æœåŠ¡æ˜¯å¦å¯ç”¨"""
        return self._available

    def _compute_hash(self, text: str) -> str:
        """
        è®¡ç®—æ–‡æœ¬çš„å“ˆå¸ŒID

        å‚æ•°:
            text: è¾“å…¥æ–‡æœ¬

        è¿”å›:
            16ä½å“ˆå¸Œå­—ç¬¦ä¸²
        """
        return hashlib.sha256(text.encode('utf-8')).hexdigest()[:16]

    def _cosine_similarity(self, emb1: np.ndarray, emb2: np.ndarray) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦

        å‚æ•°:
            emb1: å‘é‡1
            emb2: å‘é‡2

        è¿”å›:
            ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        dot_product = np.dot(emb1, emb2)
        norm1 = np.linalg.norm(emb1)
        norm2 = np.linalg.norm(emb2)

        if norm1 == 0 or norm2 == 0:
            return 0.0

        return float(dot_product / (norm1 * norm2))

    async def query(
        self,
        question: str,
        session_id: str
    ) -> Dict:
        """
        æŸ¥è¯¢ç¼“å­˜

        å‚æ•°:
            question: ç”¨æˆ·é—®é¢˜
            session_id: ä¼šè¯ID

        è¿”å›:
            å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹é”®:
            - status: "hit" | "pending_confirm" | "miss"
            - answer: ç­”æ¡ˆå†…å®¹ï¼ˆä»…å½“ hit æ—¶ï¼‰
            - cached_question: ç›¸ä¼¼é—®é¢˜ï¼ˆhit æˆ– pending_confirm æ—¶ï¼‰
            - similarity: ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆhit æˆ– pending_confirm æ—¶ï¼‰
            - confirmation_id: ç¡®è®¤IDï¼ˆä»…å½“ pending_confirm æ—¶ï¼‰
        """
        if not self._available:
            return {"status": "miss"}

        try:
            # 1. è®¡ç®—é—®é¢˜çš„embeddingï¼ˆä½¿ç”¨embedding_engineï¼‰
            question_embedding_list = self.embedding_engine.encode([question])
            question_embedding = np.array(question_embedding_list[0], dtype=np.float32)

            # 2. è·å–æ‰€æœ‰ç¼“å­˜çš„é—®é¢˜ID
            cached_ids = self.redis.zrange("cache:embeddings", 0, -1)

            if not cached_ids or len(cached_ids) == 0:
                logger.debug("ğŸ’­ ç¼“å­˜ä¸ºç©ºï¼Œé¦–æ¬¡æŸ¥è¯¢")
                return {"status": "miss"}

            logger.info(f"ğŸ” å¼€å§‹è¯­ä¹‰ç¼“å­˜æŸ¥è¯¢ - å½“å‰ç¼“å­˜: {len(cached_ids)} æ¡")

            # 3. éå†æ‰€æœ‰ç¼“å­˜æ¡ç›®ï¼Œè®¡ç®—ç›¸ä¼¼åº¦
            best_match = None
            best_similarity = 0.0
            best_id = None

            for cache_id in cached_ids:
                cache_id_str = cache_id.decode('utf-8') if isinstance(cache_id, bytes) else cache_id

                # è·å–ç¼“å­˜çš„æ•°æ®
                cached_data = self.redis.hgetall(f"cache:question:{cache_id_str}")
                if not cached_data:
                    continue

                # ååºåˆ—åŒ– embedding
                cached_embedding = np.frombuffer(
                    cached_data[b'embedding'],
                    dtype=np.float32
                )

                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                similarity = self._cosine_similarity(question_embedding, cached_embedding)

                if similarity > best_similarity:
                    best_similarity = similarity
                    best_match = cached_data
                    best_id = cache_id_str

            # 4. æ ¹æ®ç›¸ä¼¼åº¦åˆ†å±‚å¤„ç†
            logger.info(f"ğŸ¯ æœ€é«˜ç›¸ä¼¼åº¦: {best_similarity:.4f} "
                       f"(ç›´æ¥é˜ˆå€¼: {self.threshold_direct}, ç¡®è®¤é˜ˆå€¼: {self.threshold_confirm})")

            if best_similarity >= self.threshold_direct:
                # âœ… é«˜åº¦ç›¸ä¼¼ â†’ ç›´æ¥è¿”å›ç¼“å­˜
                cached_question = best_match[b'question'].decode('utf-8')
                cached_answer = best_match[b'answer'].decode('utf-8')

                logger.info(f"âœ… ç¼“å­˜ç›´æ¥å‘½ä¸­! ç›¸ä¼¼åº¦: {best_similarity:.2%}")
                logger.info(f"   ç¼“å­˜é—®é¢˜: {cached_question[:50]}...")
                logger.info(f"   å½“å‰é—®é¢˜: {question[:50]}...")

                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self._update_hit_stats(best_id, cached_question)

                return {
                    "status": "hit",
                    "answer": cached_answer,
                    "cached_question": cached_question,
                    "similarity": best_similarity
                }

            elif best_similarity >= self.threshold_confirm:
                # âš ï¸ ä¸­ç­‰ç›¸ä¼¼ â†’ éœ€è¦ç”¨æˆ·ç¡®è®¤
                cached_question = best_match[b'question'].decode('utf-8')
                cached_answer = best_match[b'answer'].decode('utf-8')

                logger.info(f"âš ï¸ å‘ç°ç›¸ä¼¼é—®é¢˜ï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤ (ç›¸ä¼¼åº¦: {best_similarity:.2%})")
                logger.info(f"   ç¼“å­˜é—®é¢˜: {cached_question[:50]}...")
                logger.info(f"   å½“å‰é—®é¢˜: {question[:50]}...")

                # ç”Ÿæˆå”¯ä¸€çš„ç¡®è®¤ID
                confirmation_id = f"{session_id}_{int(datetime.now().timestamp() * 1000)}"

                # å­˜å‚¨å¾…ç¡®è®¤æ•°æ®ï¼ˆ5åˆ†é’Ÿè¿‡æœŸï¼‰
                pending_data = {
                    "question": question,
                    "cached_question": cached_question,
                    "cached_id": best_id,
                    "similarity": best_similarity,
                    "cached_answer": cached_answer,
                    "timestamp": datetime.now().isoformat()
                }

                self.redis.setex(
                    f"cache:pending:{confirmation_id}",
                    300,  # 5åˆ†é’Ÿè¿‡æœŸ
                    json.dumps(pending_data, ensure_ascii=False)
                )

                return {
                    "status": "pending_confirm",
                    "cached_question": cached_question,
                    "similarity": best_similarity,
                    "confirmation_id": confirmation_id
                }

            else:
                # âŒ ç›¸ä¼¼åº¦å¤ªä½ â†’ ç¼“å­˜æœªå‘½ä¸­
                logger.info(f"âŒ ç¼“å­˜æœªå‘½ä¸­ (æœ€é«˜ç›¸ä¼¼åº¦: {best_similarity:.2%} < {self.threshold_confirm})")
                return {"status": "miss"}

        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜æŸ¥è¯¢å‡ºé”™: {e}", exc_info=True)
            return {"status": "miss"}

    async def confirm_cache(self, confirmation_id: str, user_confirmed: bool) -> Optional[str]:
        """
        å¤„ç†ç”¨æˆ·çš„ç¼“å­˜ç¡®è®¤

        å‚æ•°:
            confirmation_id: ç¡®è®¤ID
            user_confirmed: ç”¨æˆ·æ˜¯å¦ç¡®è®¤ä½¿ç”¨ç¼“å­˜

        è¿”å›:
            å¦‚æœç”¨æˆ·ç¡®è®¤ï¼Œè¿”å›ç¼“å­˜çš„ç­”æ¡ˆï¼›å¦åˆ™è¿”å› None
        """
        if not self._available:
            return None

        try:
            # è·å–å¾…ç¡®è®¤æ•°æ®
            pending_key = f"cache:pending:{confirmation_id}"
            pending_data_json = self.redis.get(pending_key)

            if not pending_data_json:
                logger.warning(f"âš ï¸ ç¡®è®¤IDå·²è¿‡æœŸæˆ–ä¸å­˜åœ¨: {confirmation_id}")
                return None

            pending_data = json.loads(pending_data_json.decode('utf-8'))

            if user_confirmed:
                # ç”¨æˆ·ç¡®è®¤æ˜¯ç›¸åŒé—®é¢˜ â†’ ä½¿ç”¨ç¼“å­˜ç­”æ¡ˆ
                logger.info(f"âœ… ç”¨æˆ·ç¡®è®¤ç›¸ä¼¼ï¼Œä½¿ç”¨ç¼“å­˜ç­”æ¡ˆ")
                logger.info(f"   åŸé—®é¢˜: {pending_data['cached_question'][:50]}...")
                logger.info(f"   æ–°é—®é¢˜: {pending_data['question'][:50]}...")

                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self._update_hit_stats(pending_data['cached_id'], pending_data['cached_question'])

                # å°†æ–°é—®é¢˜æ·»åŠ åˆ°ç›¸ä¼¼é—®é¢˜åˆ—è¡¨
                self._add_similar_question(
                    pending_data['cached_id'],
                    pending_data['question']
                )

                # åˆ é™¤å¾…ç¡®è®¤æ•°æ®
                self.redis.delete(pending_key)

                return pending_data['cached_answer']

            else:
                # ç”¨æˆ·å¦è®¤æ˜¯ç›¸åŒé—®é¢˜ â†’ éœ€è¦é‡æ–°æ£€ç´¢
                logger.info(f"âŒ ç”¨æˆ·å¦è®¤ç›¸ä¼¼ï¼Œå°†é‡æ–°æ£€ç´¢")
                self.redis.delete(pending_key)
                return None

        except Exception as e:
            logger.error(f"âŒ å¤„ç†ç¼“å­˜ç¡®è®¤æ—¶å‡ºé”™: {e}", exc_info=True)
            return None

    def set(
        self,
        question: str,
        answer: str,
        cache_type: str = "auto",
        quality_score: int = 0
    ):
        """
        æ·»åŠ æ–°çš„ç¼“å­˜æ¡ç›®

        å‚æ•°:
            question: é—®é¢˜æ–‡æœ¬
            answer: ç­”æ¡ˆæ–‡æœ¬
            cache_type: ç¼“å­˜ç±»å‹ ("auto" | "confirmed" | "manual")
            quality_score: è´¨é‡åˆ†æ•° (0-10, manual=10, confirmed=5, auto=0)
        """
        if not self._available:
            return

        try:
            # 1. è®¡ç®—é—®é¢˜çš„embedding
            question_embedding_list = self.embedding_engine.encode([question])
            embedding = np.array(question_embedding_list[0], dtype=np.float32)

            # 2. æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
            cache_size = self.redis.zcard("cache:embeddings")
            if cache_size >= self.max_cache_size:
                # LRU æ·˜æ±°ï¼šåˆ é™¤æœ€æ—§çš„æ¡ç›®
                oldest_ids = self.redis.zrange("cache:embeddings", 0, 0)
                if oldest_ids:
                    oldest_id = oldest_ids[0]
                    self._evict_cache(oldest_id)
                    logger.info(f"ğŸ—‘ï¸ ç¼“å­˜å·²æ»¡ï¼ŒLRUæ·˜æ±°æœ€æ—§æ¡ç›®")

            # 3. è®¡ç®—å“ˆå¸ŒID
            cache_id = self._compute_hash(question)

            # 4. å­˜å‚¨ç¼“å­˜æ•°æ®
            cache_data = {
                "question": question.encode('utf-8'),
                "answer": answer.encode('utf-8'),
                "embedding": embedding.tobytes(),
                "timestamp": datetime.now().isoformat().encode('utf-8'),
                "hit_count": b"0",
                "last_hit": b"",
                "cache_type": cache_type.encode('utf-8'),
                "quality_score": str(quality_score).encode('utf-8')
            }

            self.redis.hset(
                f"cache:question:{cache_id}",
                mapping=cache_data
            )

            # 5. æ·»åŠ åˆ°æ—¶é—´ç´¢å¼•ï¼ˆç”¨äº LRUï¼‰
            self.redis.zadd(
                "cache:embeddings",
                {cache_id: datetime.now().timestamp()}
            )

            # 6. è®¾ç½® TTL
            self.redis.expire(f"cache:question:{cache_id}", self.cache_ttl)

            # 7. åˆå§‹åŒ–çƒ­é—¨é—®é¢˜ç»Ÿè®¡ï¼ˆé¦–æ¬¡å­˜å‚¨ä¹Ÿç®—ä½œ1æ¬¡è®¿é—®ï¼‰
            self.redis.zincrby("cache:popular", 1, question)
            
            # 8. å­˜å‚¨ç¼“å­˜ç±»å‹æ ‡è®°
            self.redis.set(f"cache:type:{cache_id}", cache_type)

            logger.info(f"ğŸ’¾ æ·»åŠ åˆ°ç¼“å­˜: {cache_id[:8]}... | ç±»å‹: {cache_type} | è´¨é‡: {quality_score} | é—®é¢˜: {question[:50]}...")

        except Exception as e:
            logger.error(f"âŒ æ·»åŠ ç¼“å­˜æ—¶å‡ºé”™: {e}", exc_info=True)

    def _update_hit_stats(self, cache_id: str, question: str):
        """
        æ›´æ–°ç¼“å­˜å‘½ä¸­ç»Ÿè®¡

        å‚æ•°:
            cache_id: ç¼“å­˜æ¡ç›®ID
            question: é—®é¢˜æ–‡æœ¬
        """
        try:
            # 1. å¢åŠ è¯¥ç¼“å­˜æ¡ç›®çš„å‘½ä¸­æ¬¡æ•°
            self.redis.hincrby(f"cache:question:{cache_id}", "hit_count", 1)
            self.redis.hset(
                f"cache:question:{cache_id}",
                "last_hit",
                datetime.now().isoformat().encode('utf-8')
            )

            # 2. æ›´æ–°çƒ­é—¨é—®é¢˜æ’è¡Œï¼ˆSorted Setï¼ŒæŒ‰å‘½ä¸­æ¬¡æ•°æ’åºï¼‰
            self.redis.zincrby("cache:popular", 1, question)

            # 3. æ›´æ–° LRU æ—¶é—´æˆ³ï¼ˆæœ€è¿‘ä½¿ç”¨çš„æ’åˆ°åé¢ï¼‰
            self.redis.zadd(
                "cache:embeddings",
                {cache_id: datetime.now().timestamp()}
            )

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {e}", exc_info=True)

    def _add_similar_question(self, canonical_id: str, new_question: str):
        """
        å°†æ–°é—®é¢˜æ·»åŠ åˆ°ç›¸ä¼¼é—®é¢˜ç»„

        å‚æ•°:
            canonical_id: ä»£è¡¨æ€§é—®é¢˜çš„ID
            new_question: æ–°çš„ç›¸ä¼¼é—®é¢˜
        """
        try:
            self.redis.hincrby(
                f"cache:similar:{canonical_id}",
                new_question,
                1
            )
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ ç›¸ä¼¼é—®é¢˜æ—¶å‡ºé”™: {e}", exc_info=True)

    def _evict_cache(self, cache_id):
        """
        åˆ é™¤ç¼“å­˜æ¡ç›®ï¼ˆLRU æ·˜æ±°ï¼‰

        å‚æ•°:
            cache_id: è¦åˆ é™¤çš„ç¼“å­˜ID
        """
        try:
            cache_id_str = cache_id.decode('utf-8') if isinstance(cache_id, bytes) else cache_id

            # åˆ é™¤ä¸»æ•°æ®
            self.redis.delete(f"cache:question:{cache_id_str}")

            # ä»ç´¢å¼•ä¸­åˆ é™¤
            self.redis.zrem("cache:embeddings", cache_id_str)

            # åˆ é™¤ç›¸ä¼¼é—®é¢˜æ˜ å°„
            self.redis.delete(f"cache:similar:{cache_id_str}")

        except Exception as e:
            logger.error(f"âŒ åˆ é™¤ç¼“å­˜æ—¶å‡ºé”™: {e}", exc_info=True)

    def get_popular_questions(self, top_n: int = 3) -> List[Dict]:
        """
        è·å–æœ€çƒ­é—¨çš„é—®é¢˜ï¼ˆä¾›å‰ç«¯æ˜¾ç¤ºï¼‰

        å‚æ•°:
            top_n: è¿”å›çš„çƒ­é—¨é—®é¢˜æ•°é‡

        è¿”å›:
            çƒ­é—¨é—®é¢˜åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«:
            - question: é—®é¢˜æ–‡æœ¬
            - count: ç´¯è®¡è®¿é—®æ¬¡æ•°
            - similar_count: ç›¸ä¼¼é—®é¢˜æ•°é‡
        """
        if not self._available:
            return []

        try:
            # ä»çƒ­é—¨æ’è¡Œä¸­è·å– top Nï¼ˆæŒ‰åˆ†æ•°é™åºï¼‰
            popular = self.redis.zrevrange("cache:popular", 0, top_n - 1, withscores=True)

            result = []
            for question_bytes, count in popular:
                question = question_bytes.decode('utf-8') if isinstance(question_bytes, bytes) else question_bytes

                # è·å–è¿™ä¸ªé—®é¢˜çš„ID
                cache_id = self._compute_hash(question)

                # è·å–ç›¸ä¼¼é—®é¢˜æ•°é‡
                similar_count = self.redis.hlen(f"cache:similar:{cache_id}")

                result.append({
                    "question": question,
                    "count": int(count),
                    "similar_count": similar_count
                })

            return result

        except Exception as e:
            logger.error(f"âŒ è·å–çƒ­é—¨é—®é¢˜æ—¶å‡ºé”™: {e}", exc_info=True)
            return []

    def get_cache_stats(self) -> Dict:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

        è¿”å›:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«:
            - available: ç¼“å­˜æœåŠ¡æ˜¯å¦å¯ç”¨
            - total_entries: ç¼“å­˜æ¡ç›®æ€»æ•°
            - total_hits: æ€»å‘½ä¸­æ¬¡æ•°
            - popular_questions: çƒ­é—¨é—®é¢˜åˆ—è¡¨
            - cache_by_type: æŒ‰ç±»å‹åˆ†ç»„çš„ç¼“å­˜æ•°é‡
        """
        if not self._available:
            return {
                "available": False,
                "total_entries": 0,
                "total_hits": 0,
                "popular_questions": [],
                "cache_by_type": {}
            }

        try:
            total_entries = self.redis.zcard("cache:embeddings")

            # è®¡ç®—æ€»å‘½ä¸­æ¬¡æ•°å’ŒæŒ‰ç±»å‹ç»Ÿè®¡
            total_hits = 0
            cache_by_type = {"auto": 0, "confirmed": 0, "manual": 0}
            
            cached_ids = self.redis.zrange("cache:embeddings", 0, -1)
            for cache_id in cached_ids:
                cache_id_str = cache_id.decode('utf-8') if isinstance(cache_id, bytes) else cache_id
                
                # ç»Ÿè®¡å‘½ä¸­æ¬¡æ•°
                hit_count = self.redis.hget(f"cache:question:{cache_id_str}", "hit_count")
                if hit_count:
                    total_hits += int(hit_count.decode('utf-8') if isinstance(hit_count, bytes) else hit_count)
                
                # ç»Ÿè®¡ç¼“å­˜ç±»å‹
                cache_type = self.redis.get(f"cache:type:{cache_id_str}")
                if cache_type:
                    cache_type_str = cache_type.decode('utf-8') if isinstance(cache_type, bytes) else cache_type
                    if cache_type_str in cache_by_type:
                        cache_by_type[cache_type_str] += 1

            return {
                "available": True,
                "total_entries": total_entries,
                "total_hits": total_hits,
                "popular_questions": self.get_popular_questions(10),
                "cache_by_type": cache_by_type
            }

        except Exception as e:
            logger.error(f"âŒ è·å–ç¼“å­˜ç»Ÿè®¡æ—¶å‡ºé”™: {e}", exc_info=True)
            return {
                "available": False,
                "total_entries": 0,
                "total_hits": 0,
                "popular_questions": [],
                "cache_by_type": {}
            }
    
    def clear_cache(self, cache_types: List[str] = None) -> int:
        """
        æ¸…é™¤ç¼“å­˜
        
        å‚æ•°:
            cache_types: è¦æ¸…é™¤çš„ç¼“å­˜ç±»å‹åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºæ¸…é™¤æ‰€æœ‰
            
        è¿”å›:
            åˆ é™¤çš„ç¼“å­˜æ¡ç›®æ•°
        """
        if not self._available:
            return 0
        
        try:
            cached_ids = self.redis.zrange("cache:embeddings", 0, -1)
            deleted_count = 0
            
            for cache_id in cached_ids:
                cache_id_str = cache_id.decode('utf-8') if isinstance(cache_id, bytes) else cache_id
                
                # å¦‚æœæŒ‡å®šäº†ç±»å‹è¿‡æ»¤
                if cache_types:
                    cache_type = self.redis.get(f"cache:type:{cache_id_str}")
                    if cache_type:
                        cache_type_str = cache_type.decode('utf-8') if isinstance(cache_type, bytes) else cache_type
                        if cache_type_str not in cache_types:
                            continue
                
                # åˆ é™¤ç¼“å­˜
                self._evict_cache(cache_id_str)
                deleted_count += 1
            
            # å¦‚æœæ¸…é™¤æ‰€æœ‰ï¼Œä¹Ÿæ¸…ç©ºçƒ­é—¨é—®é¢˜
            if not cache_types:
                self.redis.delete("cache:popular")
            
            logger.info(f"ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜: {deleted_count} æ¡")
            return deleted_count
            
        except Exception as e:
            logger.error(f"âŒ æ¸…é™¤ç¼“å­˜æ—¶å‡ºé”™: {e}", exc_info=True)
            return 0
    
    def get_all_cached_questions(self, limit: int = 100) -> List[Dict]:
        """
        è·å–æ‰€æœ‰ç¼“å­˜çš„é—®é¢˜åˆ—è¡¨ï¼ˆç”¨äºç®¡ç†å‘˜æŸ¥çœ‹ï¼‰
        
        å‚æ•°:
            limit: è¿”å›çš„æœ€å¤§æ•°é‡
            
        è¿”å›:
            ç¼“å­˜é—®é¢˜åˆ—è¡¨
        """
        if not self._available:
            return []
        
        try:
            cached_ids = self.redis.zrange("cache:embeddings", 0, limit - 1)
            result = []
            
            for cache_id in cached_ids:
                cache_id_str = cache_id.decode('utf-8') if isinstance(cache_id, bytes) else cache_id
                cached_data = self.redis.hgetall(f"cache:question:{cache_id_str}")
                
                if cached_data:
                    question = cached_data[b'question'].decode('utf-8')
                    answer = cached_data.get(b'answer', b'').decode('utf-8')
                    hit_count = int(cached_data.get(b'hit_count', b'0').decode('utf-8'))
                    timestamp = cached_data.get(b'timestamp', b'').decode('utf-8')
                    cache_type = cached_data.get(b'cache_type', b'auto').decode('utf-8')
                    quality_score = int(cached_data.get(b'quality_score', b'0').decode('utf-8'))
                    
                    result.append({
                        "cache_id": cache_id_str,
                        "question": question,
                        "answer": answer,
                        "hit_count": hit_count,
                        "timestamp": timestamp,
                        "cache_type": cache_type,
                        "quality_score": quality_score
                    })
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç¼“å­˜åˆ—è¡¨æ—¶å‡ºé”™: {e}", exc_info=True)
            return []